{"/home/travis/build/npmtest/node-npmtest-s3/test.js":"/* istanbul instrument in package npmtest_s3 */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-s3/lib.npmtest_s3.js":"/* istanbul instrument in package npmtest_s3 */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_s3 = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_s3 = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-s3/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-s3 && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_s3 */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_s3\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_s3.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        local.assetsDict['/assets.npmtest_s3.rollup.js'] =\n            local.assetsDict['/assets.npmtest_s3.rollup.js'] ||\n            local.fs.readFileSync(\n                // buildCustomOrg-hack\n                local.npmtest_s3.__dirname +\n                    '/lib.npmtest_s3.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-s3/node_modules/s3/lib/index.js":"var AWS = require('aws-sdk');\nvar EventEmitter = require('events').EventEmitter;\nvar fs = require('graceful-fs');\nvar url = require('url');\nvar rimraf = require('rimraf');\nvar findit = require('findit2');\nvar Pend = require('pend');\nvar path = require('path');\nvar crypto = require('crypto');\nvar mkdirp = require('mkdirp');\nvar assert = require('assert');\nvar MultipartETag = require('./multipart_etag');\nvar fd_slicer = require('fd-slicer');\nvar mime = require('mime');\nvar StreamSink = require('streamsink');\nvar PassThrough = require('stream').PassThrough;\n\nvar MAX_PUTOBJECT_SIZE = 5 * 1024 * 1024 * 1024;\nvar MAX_DELETE_COUNT = 1000;\nvar MAX_MULTIPART_COUNT = 10000;\nvar MIN_MULTIPART_SIZE = 5 * 1024 * 1024;\n\nvar TO_UNIX_RE = new RegExp(quotemeta(path.sep), 'g');\n\nexports.createClient = function(options) {\n  return new Client(options);\n};\n\nexports.getPublicUrl = getPublicUrl;\nexports.getPublicUrlHttp = getPublicUrlHttp;\n\nexports.Client = Client;\nexports.MultipartETag = MultipartETag;\nexports.AWS = AWS;\n\nexports.MAX_PUTOBJECT_SIZE = MAX_PUTOBJECT_SIZE;\nexports.MAX_DELETE_COUNT = MAX_DELETE_COUNT;\nexports.MAX_MULTIPART_COUNT = MAX_MULTIPART_COUNT;\nexports.MIN_MULTIPART_SIZE = MIN_MULTIPART_SIZE;\n\nfunction Client(options) {\n  options = options || {};\n  this.s3 = options.s3Client || new AWS.S3(options.s3Options);\n  this.s3Pend = new Pend();\n  this.s3Pend.max = options.maxAsyncS3 || 20;\n  this.s3RetryCount = options.s3RetryCount || 3;\n  this.s3RetryDelay = options.s3RetryDelay || 1000;\n  this.multipartUploadThreshold = options.multipartUploadThreshold || (20 * 1024 * 1024);\n  this.multipartUploadSize = options.multipartUploadSize || (15 * 1024 * 1024);\n  this.multipartDownloadThreshold = options.multipartDownloadThreshold || (20 * 1024 * 1024);\n  this.multipartDownloadSize = options.multipartDownloadSize || (15 * 1024 * 1024);\n\n  if (this.multipartUploadThreshold < MIN_MULTIPART_SIZE) {\n    throw new Error(\"Minimum multipartUploadThreshold is 5MB.\");\n  }\n  if (this.multipartUploadThreshold > MAX_PUTOBJECT_SIZE) {\n    throw new Error(\"Maximum multipartUploadThreshold is 5GB.\");\n  }\n  if (this.multipartUploadSize < MIN_MULTIPART_SIZE) {\n    throw new Error(\"Minimum multipartUploadSize is 5MB.\");\n  }\n  if (this.multipartUploadSize > MAX_PUTOBJECT_SIZE) {\n    throw new Error(\"Maximum multipartUploadSize is 5GB.\");\n  }\n}\n\nClient.prototype.deleteObjects = function(s3Params) {\n  var self = this;\n  var ee = new EventEmitter();\n\n  var params = {\n    Bucket: s3Params.Bucket,\n    Delete: extend({}, s3Params.Delete),\n    MFA: s3Params.MFA,\n  };\n  var slices = chunkArray(params.Delete.Objects, MAX_DELETE_COUNT);\n  var errorOccurred = false;\n  var pend = new Pend();\n\n  ee.progressAmount = 0;\n  ee.progressTotal = params.Delete.Objects.length;\n\n  slices.forEach(uploadSlice);\n  pend.wait(function(err) {\n    if (err) {\n      ee.emit('error', err);\n      return;\n    }\n    ee.emit('end');\n  });\n  return ee;\n\n  function uploadSlice(slice) {\n    pend.go(function(cb) {\n      doWithRetry(tryDeletingObjects, self.s3RetryCount, self.s3RetryDelay, function(err, data) {\n        if (err) {\n          cb(err);\n        } else {\n          ee.progressAmount += slice.length;\n          ee.emit('progress');\n          ee.emit('data', data);\n          cb();\n        }\n      });\n    });\n\n    function tryDeletingObjects(cb) {\n      self.s3Pend.go(function(pendCb) {\n        params.Delete.Objects = slice;\n        self.s3.deleteObjects(params, function(err, data) {\n          pendCb();\n          cb(err, data);\n        });\n      });\n    }\n  }\n};\n\nClient.prototype.uploadFile = function(params) {\n  var self = this;\n  var uploader = new EventEmitter();\n  uploader.progressMd5Amount = 0;\n  uploader.progressAmount = 0;\n  uploader.progressTotal = 0;\n  uploader.abort = handleAbort;\n\n  var localFile = params.localFile;\n  var localFileStat = null;\n  var s3Params = extend({}, params.s3Params);\n  if (s3Params.ContentType === undefined) {\n    var defaultContentType = params.defaultContentType || 'application/octet-stream';\n    s3Params.ContentType = mime.lookup(localFile, defaultContentType);\n  }\n  var fatalError = false;\n  var localFileSlicer = null;\n  var parts = [];\n\n  openFile();\n\n  return uploader;\n\n  function handleError(err) {\n    if (localFileSlicer) {\n      localFileSlicer.unref();\n      localFileSlicer = null;\n    }\n    if (fatalError) return;\n    fatalError = true;\n    uploader.emit('error', err);\n  }\n\n  function handleAbort() {\n    fatalError = true;\n  }\n\n  function openFile() {\n    fs.open(localFile, 'r', function(err, fd) {\n      if (err) return handleError(err);\n      localFileSlicer = fd_slicer.createFromFd(fd, {autoClose: true});\n      localFileSlicer.on('error', handleError);\n      localFileSlicer.on('close', function() {\n        uploader.emit('fileClosed');\n      });\n\n      // keep an extra reference alive until we decide that we're completely\n      // done with the file\n      localFileSlicer.ref();\n\n      uploader.emit('fileOpened', localFileSlicer);\n\n      fs.fstat(fd, function(err, stat) {\n        if (err) return handleError(err);\n        localFileStat = stat;\n        uploader.progressTotal = stat.size;\n        startPuttingObject();\n      });\n    });\n  }\n\n  function startPuttingObject() {\n    if (localFileStat.size >= self.multipartUploadThreshold) {\n      var multipartUploadSize = self.multipartUploadSize;\n      var partsRequiredCount = Math.ceil(localFileStat.size / multipartUploadSize);\n      if (partsRequiredCount > MAX_MULTIPART_COUNT) {\n        multipartUploadSize = smallestPartSizeFromFileSize(localFileStat.size);\n      }\n      if (multipartUploadSize > MAX_PUTOBJECT_SIZE) {\n        var err = new Error(\"File size exceeds maximum object size: \" + localFile);\n        err.retryable = false;\n        handleError(err);\n        return;\n      }\n      startMultipartUpload(multipartUploadSize);\n    } else {\n      doWithRetry(tryPuttingObject, self.s3RetryCount, self.s3RetryDelay, onPutObjectDone);\n    }\n\n    function onPutObjectDone(err, data) {\n      if (fatalError) return;\n      if (err) return handleError(err);\n      if (localFileSlicer) {\n        localFileSlicer.unref();\n        localFileSlicer = null;\n      }\n      uploader.emit('end', data);\n    }\n  }\n\n  function startMultipartUpload(multipartUploadSize) {\n    doWithRetry(tryCreateMultipartUpload, self.s3RetryCount, self.s3RetryDelay, function(err, data) {\n      if (fatalError) return;\n      if (err) return handleError(err);\n      uploader.emit('data', data);\n      s3Params = {\n        Bucket: s3Params.Bucket,\n        Key: s3Params.Key,\n        SSECustomerAlgorithm: s3Params.SSECustomerAlgorithm,\n        SSECustomerKey: s3Params.SSECustomerKey,\n        SSECustomerKeyMD5: s3Params.SSECustomerKeyMD5,\n      };\n      queueAllParts(data.UploadId, multipartUploadSize);\n    });\n  }\n\n  function queueAllParts(uploadId, multipartUploadSize) {\n    var cursor = 0;\n    var nextPartNumber = 1;\n    var pend = new Pend();\n    while (cursor < localFileStat.size) {\n      var start = cursor;\n      var end = cursor + multipartUploadSize;\n      if (end > localFileStat.size) {\n        end = localFileStat.size;\n      }\n      cursor = end;\n      var part = {\n        ETag: null,\n        PartNumber: nextPartNumber++,\n      };\n      parts.push(part);\n      pend.go(makeUploadPartFn(start, end, part, uploadId));\n    }\n    pend.wait(function(err) {\n      if (fatalError) return;\n      if (err) return handleError(err);\n      completeMultipartUpload();\n    });\n  }\n\n  function makeUploadPartFn(start, end, part, uploadId) {\n    return function(cb) {\n      doWithRetry(tryUploadPart, self.s3RetryCount, self.s3RetryDelay, function(err, data) {\n        if (fatalError) return;\n        if (err) return handleError(err);\n        uploader.emit('part', data);\n        cb();\n      });\n    };\n\n    function tryUploadPart(cb) {\n      if (fatalError) return;\n      self.s3Pend.go(function(pendCb) {\n        if (fatalError) {\n          pendCb();\n          return;\n        }\n        var inStream = localFileSlicer.createReadStream({start: start, end: end});\n        var errorOccurred = false;\n        inStream.on('error', function(err) {\n          if (fatalError || errorOccurred) return;\n          handleError(err);\n        });\n        s3Params.Body = inStream;\n        s3Params.ContentLength = end - start;\n        s3Params.PartNumber = part.PartNumber;\n        s3Params.UploadId = uploadId;\n\n        var multipartETag = new MultipartETag({size: s3Params.ContentLength, count: 1});\n        var prevBytes = 0;\n        var overallDelta = 0;\n        var pend = new Pend();\n        var haveETag = pend.hold();\n        multipartETag.on('progress', function() {\n          if (fatalError || errorOccurred) return;\n          var delta = multipartETag.bytes - prevBytes;\n          prevBytes = multipartETag.bytes;\n          uploader.progressAmount += delta;\n          overallDelta += delta;\n          uploader.emit('progress');\n        });\n        multipartETag.on('end', function() {\n          if (fatalError || errorOccurred) return;\n          var delta = multipartETag.bytes - prevBytes;\n          uploader.progressAmount += delta;\n          uploader.progressTotal += (end - start) - multipartETag.bytes;\n          uploader.emit('progress');\n          haveETag();\n        });\n        inStream.pipe(multipartETag);\n        multipartETag.resume();\n\n        self.s3.uploadPart(extend({}, s3Params), function(err, data) {\n          pendCb();\n          if (fatalError || errorOccurred) return;\n          if (err) {\n            errorOccurred = true;\n            uploader.progressAmount -= overallDelta;\n            cb(err);\n            return;\n          }\n          pend.wait(function() {\n            if (fatalError) return;\n            if (!compareMultipartETag(data.ETag, multipartETag)) {\n              errorOccurred = true;\n              uploader.progressAmount -= overallDelta;\n              cb(new Error(\"ETag does not match MD5 checksum\"));\n              return;\n            }\n            part.ETag = data.ETag;\n            cb(null, data);\n          });\n        });\n      });\n    }\n  }\n\n  function completeMultipartUpload() {\n    localFileSlicer.unref();\n    localFileSlicer = null;\n    doWithRetry(tryCompleteMultipartUpload, self.s3RetryCount, self.s3RetryDelay, function(err, data) {\n      if (fatalError) return;\n      if (err) return handleError(err);\n      uploader.emit('end', data);\n    });\n  }\n\n  function tryCompleteMultipartUpload(cb) {\n    if (fatalError) return;\n    self.s3Pend.go(function(pendCb) {\n      if (fatalError) {\n        pendCb();\n        return;\n      }\n      s3Params = {\n        Bucket: s3Params.Bucket,\n        Key: s3Params.Key,\n        UploadId: s3Params.UploadId,\n        MultipartUpload: {\n          Parts: parts,\n        },\n      };\n      self.s3.completeMultipartUpload(s3Params, function(err, data) {\n        pendCb();\n        if (fatalError) return;\n        cb(err, data);\n      });\n    });\n  }\n\n  function tryCreateMultipartUpload(cb) {\n    if (fatalError) return;\n    self.s3Pend.go(function(pendCb) {\n      if (fatalError) return pendCb();\n      self.s3.createMultipartUpload(s3Params, function(err, data) {\n        pendCb();\n        if (fatalError) return;\n        cb(err, data);\n      });\n    });\n  }\n\n  function tryPuttingObject(cb) {\n    self.s3Pend.go(function(pendCb) {\n      if (fatalError) return pendCb();\n      var inStream = localFileSlicer.createReadStream();\n      inStream.on('error', handleError);\n      var pend = new Pend();\n      var multipartETag = new MultipartETag({size: localFileStat.size, count: 1});\n      pend.go(function(cb) {\n        multipartETag.on('end', function() {\n          if (fatalError) return;\n          uploader.progressAmount = multipartETag.bytes;\n          uploader.progressTotal = multipartETag.bytes;\n          uploader.emit('progress');\n          localFileStat.size = multipartETag.bytes;\n          localFileStat.multipartETag = multipartETag;\n          cb();\n        });\n      });\n      multipartETag.on('progress', function() {\n        if (fatalError) return;\n        uploader.progressAmount = multipartETag.bytes;\n        uploader.emit('progress');\n      });\n      s3Params.Body = inStream;\n      s3Params.ContentLength = localFileStat.size;\n      uploader.progressAmount = 0;\n      inStream.pipe(multipartETag);\n      multipartETag.resume();\n      self.s3.putObject(s3Params, function(err, data) {\n        pendCb();\n        if (fatalError) return;\n        if (err) {\n          cb(err);\n          return;\n        }\n        pend.wait(function() {\n          if (fatalError) return;\n          if (!compareMultipartETag(data.ETag, localFileStat.multipartETag)) {\n            cb(new Error(\"ETag does not match MD5 checksum\"));\n            return;\n          }\n          cb(null, data);\n        });\n      });\n    });\n  }\n};\n\nClient.prototype.downloadFile = function(params) {\n  var self = this;\n  var downloader = new EventEmitter();\n  var localFile = params.localFile;\n  var s3Params = extend({}, params.s3Params);\n\n  var dirPath = path.dirname(localFile);\n  downloader.progressAmount = 0;\n  mkdirp(dirPath, function(err) {\n    if (err) {\n      downloader.emit('error', err);\n      return;\n    }\n\n    doWithRetry(doDownloadWithPend, self.s3RetryCount, self.s3RetryDelay, function(err) {\n      if (err) {\n        downloader.emit('error', err);\n        return;\n      }\n      downloader.emit('end');\n    });\n  });\n\n  return downloader;\n\n  function doDownloadWithPend(cb) {\n    self.s3Pend.go(function(pendCb) {\n      doTheDownload(function(err) {\n        pendCb();\n        cb(err);\n      });\n    });\n  }\n\n  function doTheDownload(cb) {\n    var request = self.s3.getObject(s3Params);\n    var errorOccurred = false;\n    var hashCheckPend = new Pend();\n\n    request.on('httpHeaders', function(statusCode, headers, resp) {\n      if (statusCode >= 300) {\n        handleError(new Error(\"http status code \" + statusCode));\n        return;\n      }\n      var contentLength = parseInt(headers['content-length'], 10);\n      downloader.progressTotal = contentLength;\n      downloader.progressAmount = 0;\n      downloader.emit('progress');\n      downloader.emit('httpHeaders', statusCode, headers, resp);\n      var eTag = cleanETag(headers.etag);\n      var eTagCount = getETagCount(eTag);\n\n      var outStream = fs.createWriteStream(localFile);\n      var multipartETag = new MultipartETag({size: contentLength, count: eTagCount});\n      var httpStream = resp.httpResponse.createUnbufferedStream();\n\n      httpStream.on('error', handleError);\n      outStream.on('error', handleError);\n\n      hashCheckPend.go(function(cb) {\n        multipartETag.on('end', function() {\n          if (multipartETag.bytes !== contentLength) {\n            handleError(new Error(\"Downloaded size does not match Content-Length\"));\n            return;\n          }\n          if (eTagCount === 1 && !multipartETag.anyMatch(eTag)) {\n            handleError(new Error(\"ETag does not match MD5 checksum\"));\n            return;\n          }\n          cb();\n        });\n      });\n      multipartETag.on('progress', function() {\n        downloader.progressAmount = multipartETag.bytes;\n        downloader.emit('progress');\n      });\n      outStream.on('close', function() {\n        if (errorOccurred) return;\n        hashCheckPend.wait(cb);\n      });\n\n      httpStream.pipe(multipartETag);\n      httpStream.pipe(outStream);\n      multipartETag.resume();\n    });\n\n    request.send(handleError);\n\n    function handleError(err) {\n      if (!err) return;\n      if (errorOccurred) return;\n      errorOccurred = true;\n      cb(err);\n    }\n  }\n};\n\n/* params:\n *  - recursive: false\n *  - s3Params:\n *    - Bucket: params.s3Params.Bucket,\n *    - Delimiter: null,\n *    - Marker: null,\n *    - MaxKeys: null,\n *    - Prefix: prefix,\n */\nClient.prototype.listObjects = function(params) {\n  var self = this;\n  var ee = new EventEmitter();\n  var s3Details = extend({}, params.s3Params);\n  var recursive = !!params.recursive;\n  var abort = false;\n\n  ee.progressAmount = 0;\n  ee.objectsFound = 0;\n  ee.dirsFound = 0;\n  findAllS3Objects(s3Details.Marker, s3Details.Prefix, function(err, data) {\n    if (err) {\n      ee.emit('error', err);\n      return;\n    }\n    ee.emit('end');\n  });\n\n  ee.abort = function() {\n    abort = true;\n  };\n\n  return ee;\n\n  function findAllS3Objects(marker, prefix, cb) {\n    if (abort) return;\n    doWithRetry(listObjects, self.s3RetryCount, self.s3RetryDelay, function(err, data) {\n      if (abort) return;\n      if (err) return cb(err);\n\n      ee.progressAmount += 1;\n      ee.objectsFound += data.Contents.length;\n      ee.dirsFound += data.CommonPrefixes.length;\n      ee.emit('progress');\n      ee.emit('data', data);\n\n      var pend = new Pend();\n\n      if (recursive) {\n        data.CommonPrefixes.forEach(recurse);\n        data.CommonPrefixes = [];\n      }\n\n      if (data.IsTruncated) {\n        pend.go(findNext1000);\n      }\n\n      pend.wait(function(err) {\n        cb(err);\n      });\n\n      function findNext1000(cb) {\n        var nextMarker = data.NextMarker || data.Contents[data.Contents.length - 1].Key;\n        findAllS3Objects(nextMarker, prefix, cb);\n      }\n\n      function recurse(dirObj) {\n        var prefix = dirObj.Prefix;\n        pend.go(function(cb) {\n          findAllS3Objects(null, prefix, cb);\n        });\n      }\n    });\n\n    function listObjects(cb) {\n      if (abort) return;\n      self.s3Pend.go(function(pendCb) {\n        if (abort) {\n          pendCb();\n          return;\n        }\n        s3Details.Marker = marker;\n        s3Details.Prefix = prefix;\n        self.s3.listObjects(s3Details, function(err, data) {\n          pendCb();\n          if (abort) return;\n          cb(err, data);\n        });\n      });\n    }\n  }\n};\n\n/* params:\n * - deleteRemoved - delete s3 objects with no corresponding local file. default false\n * - localDir - path on local file system to sync\n * - s3Params:\n *   - Bucket (required)\n *   - Key (required)\n */\nClient.prototype.uploadDir = function(params) {\n  return syncDir(this, params, true);\n};\n\nClient.prototype.downloadDir = function(params) {\n  return syncDir(this, params, false);\n};\n\nClient.prototype.deleteDir = function(s3Params) {\n  var self = this;\n  var ee = new EventEmitter();\n  var bucket = s3Params.Bucket;\n  var mfa = s3Params.MFA;\n  var listObjectsParams = {\n    recursive: true,\n    s3Params: {\n      Bucket: bucket,\n      Prefix: s3Params.Prefix,\n    },\n  };\n  var finder = self.listObjects(listObjectsParams);\n  var pend = new Pend();\n  ee.progressAmount = 0;\n  ee.progressTotal = 0;\n  finder.on('error', function(err) {\n    ee.emit('error', err);\n  });\n  finder.on('data', function(objects) {\n    ee.progressTotal += objects.Contents.length;\n    ee.emit('progress');\n    if (objects.Contents.length > 0) {\n      pend.go(deleteThem);\n    }\n\n    function deleteThem(cb) {\n      var params = {\n        Bucket: bucket,\n        Delete: {\n          Objects: objects.Contents.map(keyOnly),\n          Quiet: true,\n        },\n        MFA: mfa,\n      };\n      var deleter = self.deleteObjects(params);\n      deleter.on('error', function(err) {\n        finder.abort();\n        ee.emit('error', err);\n      });\n      deleter.on('end', function() {\n        ee.progressAmount += objects.Contents.length;\n        ee.emit('progress');\n        cb();\n      });\n    }\n  });\n  finder.on('end', function() {\n    pend.wait(function() {\n      ee.emit('end');\n    });\n  });\n  return ee;\n};\n\nClient.prototype.copyObject = function(_s3Params) {\n  var self = this;\n  var ee = new EventEmitter();\n  var s3Params = extend({}, _s3Params);\n  delete s3Params.MFA;\n  doWithRetry(doCopyWithPend, self.s3RetryCount, self.s3RetryDelay, function(err, data) {\n    if (err) {\n      ee.emit('error', err);\n    } else {\n      ee.emit('end', data);\n    }\n  });\n  function doCopyWithPend(cb) {\n    self.s3Pend.go(function(pendCb) {\n      doTheCopy(function(err, data) {\n        pendCb();\n        cb(err, data);\n      });\n    });\n  }\n  function doTheCopy(cb) {\n    self.s3.copyObject(s3Params, cb);\n  }\n  return ee;\n};\n\nClient.prototype.moveObject = function(s3Params) {\n  var self = this;\n  var ee = new EventEmitter();\n  var copier = self.copyObject(s3Params);\n  var copySource = s3Params.CopySource;\n  var mfa = s3Params.MFA;\n  copier.on('error', function(err) {\n    ee.emit('error', err);\n  });\n  copier.on('end', function(data) {\n    ee.emit('copySuccess', data);\n    var slashIndex = copySource.indexOf('/');\n    var sourceBucket = copySource.substring(0, slashIndex);\n    var sourceKey = copySource.substring(slashIndex + 1);\n    var deleteS3Params = {\n      Bucket: sourceBucket,\n      Delete: {\n        Objects: [\n          {\n            Key: sourceKey,\n          },\n        ],\n        Quiet: true,\n      },\n      MFA: mfa,\n    };\n    var deleter = self.deleteObjects(deleteS3Params);\n    deleter.on('error', function(err) {\n      ee.emit('error', err);\n    });\n    var deleteData;\n    deleter.on('data', function(data) {\n      deleteData = data;\n    });\n    deleter.on('end', function() {\n      ee.emit('end', deleteData);\n    });\n  });\n  return ee;\n};\n\nClient.prototype.downloadBuffer = function(s3Params) {\n  var self = this;\n  var downloader = new EventEmitter();\n  s3Params = extend({}, s3Params);\n\n  downloader.progressAmount = 0;\n\n  doWithRetry(doDownloadWithPend, self.s3RetryCount, self.s3RetryDelay, function(err, buffer) {\n    if (err) {\n      downloader.emit('error', err);\n      return;\n    }\n    downloader.emit('end', buffer);\n  });\n\n  return downloader;\n\n  function doDownloadWithPend(cb) {\n    self.s3Pend.go(function(pendCb) {\n      doTheDownload(function(err, buffer) {\n        pendCb();\n        cb(err, buffer);\n      });\n    });\n  }\n\n  function doTheDownload(cb) {\n    var errorOccurred = false;\n    var request = self.s3.getObject(s3Params);\n    var hashCheckPend = new Pend();\n    request.on('httpHeaders', function(statusCode, headers, resp) {\n      if (statusCode >= 300) {\n        handleError(new Error(\"http status code \" + statusCode));\n        return;\n      }\n      var contentLength = parseInt(headers['content-length'], 10);\n      downloader.progressTotal = contentLength;\n      downloader.progressAmount = 0;\n      downloader.emit('progress');\n      downloader.emit('httpHeaders', statusCode, headers, resp);\n      var eTag = cleanETag(headers.etag);\n      var eTagCount = getETagCount(eTag);\n\n      var outStream = new StreamSink();\n      var multipartETag = new MultipartETag({size: contentLength, count: eTagCount});\n      var httpStream = resp.httpResponse.createUnbufferedStream();\n\n      httpStream.on('error', handleError);\n      outStream.on('error', handleError);\n\n      hashCheckPend.go(function(cb) {\n        multipartETag.on('end', function() {\n          if (multipartETag.bytes !== contentLength) {\n            handleError(new Error(\"Downloaded size does not match Content-Length\"));\n            return;\n          }\n          if (eTagCount === 1 && !multipartETag.anyMatch(eTag)) {\n            handleError(new Error(\"ETag does not match MD5 checksum\"));\n            return;\n          }\n          cb();\n        });\n      });\n      multipartETag.on('progress', function() {\n        downloader.progressAmount = multipartETag.bytes;\n        downloader.emit('progress');\n      });\n      outStream.on('finish', function() {\n        if (errorOccurred) return;\n        hashCheckPend.wait(function() {\n          cb(null, outStream.toBuffer());\n        });\n      });\n\n      httpStream.pipe(multipartETag);\n      httpStream.pipe(outStream);\n      multipartETag.resume();\n    });\n\n    request.send(handleError);\n\n    function handleError(err) {\n      if (!err) return;\n      if (errorOccurred) return;\n      errorOccurred = true;\n      cb(err);\n    }\n  }\n};\n\nClient.prototype.downloadStream = function(s3Params) {\n  var self = this;\n  var downloadStream = new PassThrough();\n  s3Params = extend({}, s3Params);\n\n  doDownloadWithPend(function(err) {\n    if (err) downloadStream.emit('error', err);\n  });\n  return downloadStream;\n\n  function doDownloadWithPend(cb) {\n    self.s3Pend.go(function(pendCb) {\n      doTheDownload(function(err) {\n        pendCb();\n        cb(err);\n      });\n    });\n  }\n\n  function doTheDownload(cb) {\n    var errorOccurred = false;\n    var request = self.s3.getObject(s3Params);\n    var hashCheckPend = new Pend();\n    request.on('httpHeaders', function(statusCode, headers, resp) {\n      if (statusCode >= 300) {\n        handleError(new Error(\"http status code \" + statusCode));\n        return;\n      }\n      downloadStream.emit('httpHeaders', statusCode, headers, resp);\n      var httpStream = resp.httpResponse.createUnbufferedStream();\n\n      httpStream.on('error', handleError);\n\n      downloadStream.on('finish', function() {\n        if (errorOccurred) return;\n        cb();\n      });\n\n      httpStream.pipe(downloadStream);\n    });\n\n    request.send(handleError);\n\n    function handleError(err) {\n      if (!err) return;\n      if (errorOccurred) return;\n      errorOccurred = true;\n      cb(err);\n    }\n  }\n};\n\nfunction syncDir(self, params, directionIsToS3) {\n  var ee = new EventEmitter();\n  var finditOpts = {\n    fs: fs,\n    followSymlinks: (params.followSymlinks == null) ? true : !!params.followSymlinks,\n  };\n  var localDir = params.localDir;\n  var deleteRemoved = params.deleteRemoved === true;\n  var fatalError = false;\n  var prefix = params.s3Params.Prefix ? ensureSlash(params.s3Params.Prefix) : '';\n  var bucket = params.s3Params.Bucket;\n  var listObjectsParams = {\n    recursive: true,\n    s3Params: {\n      Bucket: bucket,\n      Marker: null,\n      MaxKeys: null,\n      Prefix: prefix,\n    },\n  };\n  var getS3Params = params.getS3Params;\n  var baseUpDownS3Params = extend({}, params.s3Params);\n  var upDownFileParams = {\n    localFile: null,\n    s3Params: baseUpDownS3Params,\n    defaultContentType: params.defaultContentType,\n  };\n  delete upDownFileParams.s3Params.Prefix;\n\n  ee.progressAmount = 0;\n  ee.progressTotal = 0;\n  ee.progressMd5Amount = 0;\n  ee.progressMd5Total = 0;\n  ee.objectsFound = 0;\n  ee.filesFound = 0;\n  ee.deleteAmount = 0;\n  ee.deleteTotal = 0;\n  ee.doneFindingFiles = false;\n  ee.doneFindingObjects = false;\n  ee.doneMd5 = false;\n\n  var allLocalFiles = [];\n  var allS3Objects = [];\n  var localFileCursor = 0;\n  var s3ObjectCursor = 0;\n  var objectsToDelete = [];\n\n  findAllS3Objects();\n  startFindAllFiles();\n\n  return ee;\n\n  function flushDeletes() {\n    if (objectsToDelete.length === 0) return;\n    var thisObjectsToDelete = objectsToDelete;\n    objectsToDelete = [];\n    var params = {\n      Bucket: bucket,\n      Delete: {\n        Objects: thisObjectsToDelete,\n        Quiet: true,\n      },\n    };\n    var deleter = self.deleteObjects(params);\n    deleter.on('error', handleError);\n    deleter.on('end', function() {\n      if (fatalError) return;\n      ee.deleteAmount += thisObjectsToDelete.length;\n      ee.emit('progress');\n      checkDoMoreWork();\n    });\n  }\n\n  function checkDoMoreWork() {\n    if (fatalError) return;\n\n    var localFileStat = allLocalFiles[localFileCursor];\n    var s3Object = allS3Objects[s3ObjectCursor];\n\n    // need to wait for a file or object. checkDoMoreWork will get called\n    // again when that happens.\n    if (!localFileStat && !ee.doneMd5) return;\n    if (!s3Object && !ee.doneFindingObjects) return;\n\n    // need to wait until the md5 is done computing for the local file\n    if (localFileStat && !localFileStat.multipartETag) return;\n\n    // localFileStat or s3Object could still be null - in that case we have\n    // reached the real end of the list.\n\n    // if they're both null, we've reached the true end\n    if (!localFileStat && !s3Object) {\n      // if we don't have any pending deletes or uploads, we're actually done\n      flushDeletes();\n      if (ee.deleteAmount >= ee.deleteTotal &&\n          ee.progressAmount >= ee.progressTotal)\n      {\n        ee.emit('end');\n        // prevent checkDoMoreWork from doing any more work\n        fatalError = true;\n      }\n      // either way, there's nothing else to do in this method\n      return;\n    }\n\n    // special case for directories when deleteRemoved is true and we're\n    // downloading a dir from S3. We don't add directories to the list\n    // unless this case is true, so we assert that fact here.\n    if (localFileStat && localFileStat.isDirectory()) {\n      assert.ok(!directionIsToS3);\n      assert.ok(deleteRemoved);\n\n      localFileCursor += 1;\n      setImmediate(checkDoMoreWork);\n\n      if (!s3Object || s3Object.key.indexOf(localFileStat.s3Path) !== 0) {\n        deleteLocalDir();\n      }\n      return;\n    }\n\n    if (directionIsToS3) {\n      if (!localFileStat) {\n        deleteS3Object();\n      } else if (!s3Object) {\n        uploadLocalFile();\n      } else if (localFileStat.s3Path < s3Object.key) {\n        uploadLocalFile();\n      } else if (localFileStat.s3Path > s3Object.key) {\n        deleteS3Object();\n      } else if (!compareMultipartETag(s3Object.ETag, localFileStat.multipartETag)){\n        // both file cursor and s3 cursor should increment\n        s3ObjectCursor += 1;\n        uploadLocalFile();\n      } else {\n        skipThisOne();\n      }\n    } else {\n      if (!localFileStat) {\n        downloadS3Object();\n      } else if (!s3Object) {\n        deleteLocalFile();\n      } else if (localFileStat.s3Path < s3Object.key) {\n        deleteLocalFile();\n      } else if (localFileStat.s3Path > s3Object.key) {\n        downloadS3Object();\n      } else if (!compareMultipartETag(s3Object.ETag, localFileStat.multipartETag)){\n        // both file cursor and s3 cursor should increment\n        localFileCursor += 1;\n        downloadS3Object();\n      } else {\n        skipThisOne();\n      }\n    }\n\n    function deleteLocalDir() {\n      var fullPath = path.join(localDir, localFileStat.path);\n      ee.deleteTotal += 1;\n      rimraf(fullPath, function(err) {\n        if (fatalError) return;\n        if (err && err.code !== 'ENOENT') return handleError(err);\n        ee.deleteAmount += 1;\n        ee.emit('progress');\n        checkDoMoreWork();\n      });\n    }\n\n    function deleteLocalFile() {\n      localFileCursor += 1;\n      setImmediate(checkDoMoreWork);\n      if (!deleteRemoved) return;\n      ee.deleteTotal += 1;\n      var fullPath = path.join(localDir, localFileStat.path);\n      fs.unlink(fullPath, function(err) {\n        if (fatalError) return;\n        if (err && err.code !== 'ENOENT') return handleError(err);\n        ee.deleteAmount += 1;\n        ee.emit('progress');\n        checkDoMoreWork();\n      });\n    }\n\n    function downloadS3Object() {\n      s3ObjectCursor += 1;\n      setImmediate(checkDoMoreWork);\n      var fullPath = path.join(localDir, toNativeSep(s3Object.key));\n\n      if (getS3Params) {\n        getS3Params(fullPath, s3Object, haveS3Params);\n      } else {\n        startDownload();\n      }\n\n      function haveS3Params(err, s3Params) {\n        if (fatalError) return;\n        if (err) return handleError(err);\n\n        if (!s3Params) {\n          // user has decided to skip this file\n          return;\n        }\n\n        upDownFileParams.s3Params = extend(extend({}, baseUpDownS3Params), s3Params);\n        startDownload();\n      }\n\n      function startDownload() {\n        ee.progressTotal += s3Object.Size;\n        var fullKey = s3Object.Key;\n        upDownFileParams.s3Params.Key = fullKey;\n        upDownFileParams.localFile = fullPath;\n        var downloader = self.downloadFile(upDownFileParams);\n        var prevAmountDone = 0;\n        ee.emit('fileDownloadStart', fullPath, fullKey);\n        downloader.on('error', handleError);\n        downloader.on('progress', function() {\n          if (fatalError) return;\n          var delta = downloader.progressAmount - prevAmountDone;\n          prevAmountDone = downloader.progressAmount;\n          ee.progressAmount += delta;\n          ee.emit('progress');\n        });\n        downloader.on('end', function() {\n          ee.emit('fileDownloadEnd', fullPath, fullKey);\n          checkDoMoreWork();\n        });\n      }\n    }\n\n    function skipThisOne() {\n      s3ObjectCursor += 1;\n      localFileCursor += 1;\n      setImmediate(checkDoMoreWork);\n    }\n\n    function uploadLocalFile() {\n      localFileCursor += 1;\n      setImmediate(checkDoMoreWork);\n      var fullPath = path.join(localDir, localFileStat.path);\n\n      if (getS3Params) {\n        getS3Params(fullPath, localFileStat, haveS3Params);\n      } else {\n        upDownFileParams.s3Params = baseUpDownS3Params;\n        startUpload();\n      }\n\n      function haveS3Params(err, s3Params) {\n        if (fatalError) return;\n        if (err) return handleError(err);\n\n        if (!s3Params) {\n          // user has decided to skip this file\n          return;\n        }\n\n        upDownFileParams.s3Params = extend(extend({}, baseUpDownS3Params), s3Params);\n        startUpload();\n      }\n\n      function startUpload() {\n        ee.progressTotal += localFileStat.size;\n        var fullKey = prefix + localFileStat.s3Path;\n        upDownFileParams.s3Params.Key = fullKey;\n        upDownFileParams.localFile = fullPath;\n        var uploader = self.uploadFile(upDownFileParams);\n        var prevAmountDone = 0;\n        var prevAmountTotal = localFileStat.size;\n        ee.emit('fileUploadStart', fullPath, fullKey);\n        uploader.on('error', handleError);\n        uploader.on('progress', function() {\n          if (fatalError) return;\n          var amountDelta = uploader.progressAmount - prevAmountDone;\n          prevAmountDone = uploader.progressAmount;\n          ee.progressAmount += amountDelta;\n\n          var totalDelta = uploader.progressTotal - prevAmountTotal;\n          prevAmountTotal = uploader.progressTotal;\n          ee.progressTotal += totalDelta;\n\n          ee.emit('progress');\n        });\n        uploader.on('end', function() {\n          ee.emit('fileUploadEnd', fullPath, fullKey);\n          checkDoMoreWork();\n        });\n      }\n    }\n\n    function deleteS3Object() {\n      s3ObjectCursor += 1;\n      setImmediate(checkDoMoreWork);\n      if (!deleteRemoved) return;\n      objectsToDelete.push({Key: s3Object.Key});\n      ee.deleteTotal += 1;\n      ee.emit('progress');\n      assert.ok(objectsToDelete.length <= 1000);\n      if (objectsToDelete.length === 1000) {\n        flushDeletes();\n      }\n    }\n  }\n\n  function handleError(err) {\n    if (fatalError) return;\n    fatalError = true;\n    ee.emit('error', err);\n  }\n\n  function findAllS3Objects() {\n    var finder = self.listObjects(listObjectsParams);\n    finder.on('error', handleError);\n    finder.on('data', function(data) {\n      if (fatalError) return;\n      ee.objectsFound += data.Contents.length;\n      ee.emit('progress');\n      data.Contents.forEach(function(object) {\n        object.key = object.Key.substring(prefix.length);\n        allS3Objects.push(object);\n      });\n      checkDoMoreWork();\n    });\n    finder.on('end', function() {\n      if (fatalError) return;\n      ee.doneFindingObjects = true;\n      ee.emit('progress');\n      checkDoMoreWork();\n    });\n  }\n\n  function startFindAllFiles() {\n    findAllFiles(function(err) {\n      if (fatalError) return;\n      if (err) return handleError(err);\n\n      ee.doneFindingFiles = true;\n      ee.emit('progress');\n\n      allLocalFiles.sort(function(a, b) {\n        if (a.s3Path < b.s3Path) {\n          return -1;\n        } else if (a.s3Path > b.s3Path) {\n          return 1;\n        } else {\n          return 0;\n        }\n      });\n      startComputingMd5Sums();\n    });\n  }\n\n  function startComputingMd5Sums() {\n    var index = 0;\n    computeOne();\n\n    function computeOne() {\n      if (fatalError) return;\n      var localFileStat = allLocalFiles[index];\n      if (!localFileStat) {\n        ee.doneMd5 = true;\n        ee.emit('progress');\n        checkDoMoreWork();\n        return;\n      }\n      if (localFileStat.multipartETag) {\n        index += 1;\n        setImmediate(computeOne);\n        return;\n      }\n      var fullPath = path.join(localDir, localFileStat.path);\n      var inStream = fs.createReadStream(fullPath);\n      var multipartETag = new MultipartETag();\n      inStream.on('error', handleError);\n      var prevBytes = 0;\n      multipartETag.on('progress', function() {\n        var delta = multipartETag.bytes - prevBytes;\n        prevBytes = multipartETag.bytes;\n        ee.progressMd5Amount += delta;\n      });\n      multipartETag.on('end', function() {\n        if (fatalError) return;\n        localFileStat.multipartETag = multipartETag;\n        checkDoMoreWork();\n        ee.emit('progress');\n        index += 1;\n        computeOne();\n      });\n      inStream.pipe(multipartETag);\n      multipartETag.resume();\n    }\n  }\n\n  function findAllFiles(cb) {\n    var dirWithSlash = ensureSep(localDir);\n    var walker = findit(dirWithSlash, finditOpts);\n    walker.on('error', function(err) {\n      walker.stop();\n      // when uploading, we don't want to delete based on a nonexistent source directory\n      // but when downloading, the destination directory does not have to exist.\n      if (!directionIsToS3 && err.path === dirWithSlash && err.code === 'ENOENT') {\n        cb();\n      } else {\n        cb(err);\n      }\n    });\n    walker.on('directory', function(dir, stat, stop, linkPath) {\n      if (fatalError) return walker.stop();\n      // we only need to save directories when deleteRemoved is true\n      // and we're syncing to disk from s3\n      if (!deleteRemoved || directionIsToS3) return;\n      var relPath = path.relative(localDir, linkPath || dir);\n      if (relPath === '') return;\n      stat.path = relPath;\n      stat.s3Path = toUnixSep(relPath) + '/';\n      stat.multipartETag = new MultipartETag();\n      allLocalFiles.push(stat);\n    });\n    walker.on('file', function(file, stat, linkPath) {\n      if (fatalError) return walker.stop();\n      var relPath = path.relative(localDir, linkPath || file);\n      stat.path = relPath;\n      stat.s3Path = toUnixSep(relPath);\n      ee.filesFound += 1;\n      ee.progressMd5Total += stat.size;\n      ee.emit('progress');\n      allLocalFiles.push(stat);\n    });\n    walker.on('end', function() {\n      cb();\n    });\n  }\n}\n\nfunction ensureChar(str, c) {\n  return (str[str.length - 1] === c) ? str : (str + c);\n}\n\nfunction ensureSep(dir) {\n  return ensureChar(dir, path.sep);\n}\n\nfunction ensureSlash(dir) {\n  return ensureChar(dir, '/');\n}\n\nfunction doWithRetry(fn, tryCount, delay, cb) {\n  var tryIndex = 0;\n\n  tryOnce();\n\n  function tryOnce() {\n    fn(function(err, result) {\n      if (err) {\n        if (err.retryable === false) {\n          cb(err);\n        } else {\n          tryIndex += 1;\n          if (tryIndex >= tryCount) {\n            cb(err);\n          } else {\n            setTimeout(tryOnce, delay);\n          }\n        }\n      } else {\n        cb(null, result);\n      }\n    });\n  }\n}\n\nfunction extend(target, source) {\n  for (var propName in source) {\n    target[propName] = source[propName];\n  }\n  return target;\n}\n\nfunction chunkArray(array, maxLength) {\n  var slices = [array];\n  while (slices[slices.length - 1].length > maxLength) {\n    slices.push(slices[slices.length - 1].splice(maxLength));\n  }\n  return slices;\n}\n\nfunction cleanETag(eTag) {\n  return eTag ? eTag.replace(/^\\s*'?\\s*\"?\\s*(.*?)\\s*\"?\\s*'?\\s*$/, \"$1\") : \"\";\n}\n\nfunction compareMultipartETag(eTag, multipartETag) {\n  return multipartETag.anyMatch(cleanETag(eTag));\n}\n\nfunction getETagCount(eTag) {\n  var match = (eTag || \"\").match(/[a-fA-F0-9]{32}-(\\d+)$/);\n  return match ? parseInt(match[1], 10) : 1;\n}\n\nfunction keyOnly(item) {\n  return {\n    Key: item.Key,\n    VersionId: item.VersionId,\n  };\n}\n\nfunction encodeSpecialCharacters(filename) {\n  // Note: these characters are valid in URIs, but S3 does not like them for\n  // some reason.\n  return encodeURI(filename).replace(/[!'()* ]/g, function (char) {\n    return '%' + char.charCodeAt(0).toString(16);\n  });\n}\n\nfunction getPublicUrl(bucket, key, bucketLocation) {\n  var nonStandardBucketLocation = (bucketLocation && bucketLocation !== 'us-east-1');\n  var hostnamePrefix = nonStandardBucketLocation ? (\"s3-\" + bucketLocation) : \"s3\";\n  var parts = {\n    protocol: \"https:\",\n    hostname: hostnamePrefix + \".amazonaws.com\",\n    pathname: \"/\" + bucket + \"/\" + encodeSpecialCharacters(key),\n  };\n  return url.format(parts);\n}\n\nfunction getPublicUrlHttp(bucket, key) {\n  var parts = {\n    protocol: \"http:\",\n    hostname: bucket + \".s3.amazonaws.com\",\n    pathname: \"/\" + encodeSpecialCharacters(key),\n  };\n  return url.format(parts);\n}\n\nfunction toUnixSep(str) {\n  return str.replace(TO_UNIX_RE, \"/\");\n}\n\nfunction toNativeSep(str) {\n  return str.replace(/\\//g, path.sep);\n}\n\nfunction quotemeta(str) {\n    return String(str).replace(/(\\W)/g, '\\\\$1');\n}\n\nfunction smallestPartSizeFromFileSize(fileSize) {\n  var partSize = Math.ceil(fileSize / MAX_MULTIPART_COUNT);\n  return (partSize < MIN_MULTIPART_SIZE) ? MIN_MULTIPART_SIZE : partSize;\n}\n","/home/travis/build/npmtest/node-npmtest-s3/node_modules/s3/lib/multipart_etag.js":"var Transform = require('stream').Transform;\nvar util = require('util');\nvar crypto = require('crypto');\n\n/* For objects uploaded via a single request to S3, the ETag is simply the hex\n * string of the MD5 digest. However for multipart uploads, the ETag is more\n * complicated. It is the MD5 digest of each part concatenated, and then the\n * MD5 digest of *that*, followed by '-', followed by the part count.\n *\n * Sadly, this means there is no way to be sure whether a local file matches a\n * remote object. The best we can do is hope that the software used to upload\n * to S3 used a fixed part size, and that it was one of a few common sizes.\n */\n\nvar maximumUploadSize = 5 * 1024 * 1024 * 1024;\nvar commonUploadSize1 = 10 * 1024 * 1024;\nvar commonUploadSize2 = 15 * 1024 * 1024;\nvar minimumUploadSize = 5 * 1024 * 1024;\n\nmodule.exports = MultipartETag;\n\nutil.inherits(MultipartETag, Transform);\nfunction MultipartETag(options) {\n  options = options || {};\n  Transform.call(this, options);\n  var sizes = [\n    maximumUploadSize,\n    minimumUploadSize,\n    commonUploadSize1,\n    commonUploadSize2,\n  ];\n  if (options.size != null && options.count != null) {\n    if (options.count === 1) {\n      sizes = [maximumUploadSize];\n    } else {\n      sizes.push(guessPartSizeFromSizeAndCount(options.size, options.count));\n    }\n  }\n  this.sums = [];\n  this.bytes = 0;\n  this.digest = null; // if it is less than maximumUploadSize\n  this.done = false;\n  for (var i = 0; i < sizes.length; i += 1) {\n    this.sums.push({\n      size: sizes[i],\n      hash: crypto.createHash('md5'),\n      amtWritten: 0,\n      digests: [],\n      eTag: null,\n    });\n  }\n}\n\nMultipartETag.prototype._transform = function(chunk, encoding, callback) {\n  this.bytes += chunk.length;\n  for (var i = 0; i < this.sums.length; i += 1) {\n    var sumObj = this.sums[i];\n    var newAmtWritten = sumObj.amtWritten + chunk.length;\n    if (newAmtWritten <= sumObj.size) {\n      sumObj.amtWritten = newAmtWritten;\n      sumObj.hash.update(chunk, encoding);\n    } else {\n      var finalBytes = sumObj.size - sumObj.amtWritten;\n      sumObj.hash.update(chunk.slice(0, finalBytes), encoding);\n      sumObj.digests.push(sumObj.hash.digest());\n      sumObj.hash = crypto.createHash('md5');\n      sumObj.hash.update(chunk.slice(finalBytes), encoding);\n      sumObj.amtWritten = chunk.length - finalBytes;\n    }\n  }\n  this.emit('progress');\n  callback();\n};\n\nMultipartETag.prototype._flush = function(callback) {\n  for (var i = 0; i < this.sums.length; i += 1) {\n    var sumObj = this.sums[i];\n    var digest = sumObj.hash.digest();\n    sumObj.digests.push(digest);\n    var finalHash = crypto.createHash('md5');\n    for (var partIndex = 0; partIndex < sumObj.digests.length; partIndex += 1) {\n      digest = sumObj.digests[partIndex];\n      finalHash.update(digest);\n    }\n    sumObj.eTag = finalHash.digest('hex') + '-' + sumObj.digests.length;\n    if (i === 0 && sumObj.digests.length === 1) {\n      this.digest = digest;\n    }\n  }\n  this.done = true;\n  this.push(null);\n  callback();\n};\n\nMultipartETag.prototype.anyMatch = function(eTag) {\n  if (this.digest && this.digest.toString('hex') === eTag) {\n    return true;\n  }\n  for (var i = 0; i < this.sums.length; i += 1) {\n    if (this.sums[i].eTag === eTag) {\n      return true;\n    }\n  }\n  return false;\n};\n\nfunction guessPartSizeFromSizeAndCount(size, count) {\n  var divided = size / count;\n  var floored = Math.floor(divided);\n  return (divided === floored) ? divided : (floored + 1);\n}\n"}